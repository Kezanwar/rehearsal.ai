# Rehearsal.AI Session Data Structures

## Overview

Session processing produces four data outputs stored on the `sessions` table:

- `segments` (JSONB) — audio segmentation from Go service
- `transcript` (JSONB) — timestamped speech transcription from Whisper
- `transcript_text` (TEXT) — flattened text for full-text search
- `summary` (TEXT) — AI-generated analysis from Claude

---

## `segments`

Output from the Go segmentation service. Classifies audio into speech, music, or silence.

```json
[
  { "type": "speech", "start": 0.0, "end": 45.2 },
  { "type": "music", "start": 45.2, "end": 182.5 },
  { "type": "speech", "start": 182.5, "end": 210.8 },
  { "type": "silence", "start": 210.8, "end": 215.0 },
  { "type": "music", "start": 215.0, "end": 390.2 },
  { "type": "speech", "start": 390.2, "end": 425.1 }
]
```

| Field | Type | Description |
|-------|------|-------------|
| `type` | string | `"speech"` \| `"music"` \| `"silence"` |
| `start` | float | Start time in seconds |
| `end` | float | End time in seconds |

---

## `transcript`

Whisper output for speech segments only. Includes speaker diarization.

```json
[
  {
    "start": 0.0,
    "end": 12.4,
    "speaker": 1,
    "text": "Alright let's run through the verse again, I think the tempo was a bit off"
  },
  {
    "start": 12.4,
    "end": 28.1,
    "speaker": 2,
    "text": "Yeah I reckon we should slow it down a touch, maybe like 110 BPM?"
  },
  {
    "start": 28.1,
    "end": 45.2,
    "speaker": 1,
    "text": "Cool let's try that, and watch the transition into the chorus"
  },
  {
    "start": 182.5,
    "end": 210.8,
    "speaker": 1,
    "text": "That was better! But the bridge still needs work, let's take it from the top"
  }
]
```

| Field | Type | Description |
|-------|------|-------------|
| `start` | float | Start time in seconds |
| `end` | float | End time in seconds |
| `speaker` | int | Speaker identifier (1, 2, 3...) |
| `text` | string | Transcribed speech |

---

## `transcript_text`

Flattened plain text version for full-text search. Generated by concatenating all `transcript` text fields.

```
Alright let's run through the verse again, I think the tempo was a bit off. Yeah I reckon we should slow it down a touch, maybe like 110 BPM? Cool let's try that, and watch the transition into the chorus. That was better! But the bridge still needs work, let's take it from the top.
```

Enables queries like:

```sql
SELECT * FROM sessions 
WHERE user_uuid = '...' 
AND transcript_text ILIKE '%bridge%'
```

---

## `summary`

Claude's AI-generated analysis of the session based on the transcript.

```
Rehearsal focused on tightening the verse tempo. Agreed to reduce from ~115 to 110 BPM. Bridge section flagged for further work. Chorus transition improving.
```

---

## Usage

The `start`/`end` times enable a timeline UI — tap a transcript chunk to jump to that point in the audio playback.

```typescript
// Example: find transcript chunk for current playback position
const currentChunk = transcript.find(
  chunk => currentTime >= chunk.start && currentTime <= chunk.end
);
```
